{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "GANdam-Ray-PBT-Lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neil-tan/CU-Analog/blob/master/GANdam_Ray_PBT_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs_ZyVxJIpws",
        "colab_type": "text"
      },
      "source": [
        "# DCGAN Lightning GANdam\n",
        "Fully Connected for Generators and Discriminators on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N4QIR3mfyqe",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcnNMxB1nNBf",
        "colab_type": "text"
      },
      "source": [
        "### Path\n",
        "Please ensure Colab_results folder exists at the root of your Google Drive\n",
        "\n",
        "Or, you may comment out Google Drive and set log_path manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu7mjOZch7ne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81df0884-1631-425f-cea8-25113e4ca7e4"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from tempfile import mkdtemp\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive Mounting\n",
        "gdrive_mount_path = '/content/gdrive'\n",
        "gdrive_save_path = 'My Drive/Colab_results'\n",
        "drive.mount(gdrive_mount_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbjjiv3BiH1K",
        "colab_type": "text"
      },
      "source": [
        "#### Log Path\n",
        "Create the log directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8F3bIIYTiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "247a2a57-8c39-46d3-ad08-21241de96545"
      },
      "source": [
        "save_log_filename = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S-GANdam_BAYSIAN_SWEEP\")\n",
        "log_path = os.path.join(gdrive_mount_path, gdrive_save_path, save_log_filename)\n",
        "\n",
        "os.mkdir(log_path)\n",
        "\n",
        "print(log_path + \" exists: \", os.path.exists(log_path))\n",
        "data_dir = mkdtemp(prefix=\"GANdam_data_\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab_results/12-08-2020_15_54_15-GANdam_BAYSIAN_SWEEP exists:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGkdrQLVifD2",
        "colab_type": "text"
      },
      "source": [
        "#### Data Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHNgu50XieA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db03dd6a-34b5-423c-fb34-a71a1913894a"
      },
      "source": [
        "gdrive_dataset_path = \"My Drive/dataset\"\n",
        "data_zip_path = os.path.join(gdrive_mount_path, gdrive_dataset_path, \"GANdam.zip\")\n",
        "\n",
        "# data_unzip_process = os.popen(\"unzip \" + data_zip_path.replace(\" \", \"\\ \") + \" -d .\")\n",
        "os.system(\"unzip \" + data_zip_path.replace(\" \", \"\\ \") + \" -d .\")\n",
        "\n",
        "dataset_path = os.path.abspath(\"GANdam\")\n",
        "print(dataset_path + \" exists: \", os.path.exists(dataset_path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GANdam exists:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xgkfft_nZwg",
        "colab_type": "text"
      },
      "source": [
        "### Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_fPNHlAJVPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture --no-stderr\n",
        "  \n",
        "!pip install matplotlib pytorch-lightning bayesian-optimization\n",
        "\n",
        "# Ray Tune latest snapshot: https://docs.ray.io/en/latest/installation.html\n",
        "!pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n",
        "\n",
        "# previous used version:\n",
        "#!pip install -U https://ray-wheels.s3-us-west-2.amazonaws.com/master/0c3b9ebeef167a9eeb6eed9fb18f328ecb5a3c6f/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n",
        "\n",
        "!python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCyJED54Ipwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import threading\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "from functools import partial\n",
        "from argparse import Namespace\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder \n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import ray\n",
        "import ray.tune as tune\n",
        "from ray.tune import Trainable, run, sample_from, JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, MedianStoppingRule, PopulationBasedTraining\n",
        "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
        "\n",
        "from tensorboard import notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQEg1Jmkf6SC",
        "colab_type": "text"
      },
      "source": [
        "# Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTMb9Z7xIpw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator_Conv(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator_Conv, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        ngf = 64\n",
        "        nc = 3\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(in_channels=self.latent_dim,\n",
        "                               out_channels=ngf * 4,\n",
        "                               kernel_size=5,\n",
        "                               stride=1,\n",
        "                               padding=0,\n",
        "                               bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(in_channels=ngf * 4,\n",
        "                               out_channels=ngf * 4,\n",
        "                               kernel_size=6,\n",
        "                               stride=2, \n",
        "                               padding=0, \n",
        "                               bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(in_channels=ngf * 4,\n",
        "                               out_channels=ngf * 2,\n",
        "                               kernel_size=5,\n",
        "                               stride=2,\n",
        "                               padding=0,\n",
        "                               bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 14 x 14\n",
        "            nn.ConvTranspose2d(in_channels=ngf * 2,\n",
        "                               out_channels=ngf,\n",
        "                               kernel_size=3,\n",
        "                               stride=2,\n",
        "                               padding=0,\n",
        "                               bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(in_channels=ngf,\n",
        "                               out_channels=nc,\n",
        "                               kernel_size=4,\n",
        "                               stride=2,\n",
        "                               padding=0,\n",
        "                               bias=False),\n",
        "            nn.BatchNorm2d(nc),\n",
        "            nn.Tanh(),\n",
        "            # state size. (nc = 1) x 28 x 28\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "      input_4d = input.unsqueeze(2).unsqueeze_(3)\n",
        "      return self.main(input_4d)\n",
        "\n",
        "    def print_summary(self, input_size=None):\n",
        "      from torchsummary import summary\n",
        "      print(self)\n",
        "\n",
        "      if input_size is None:\n",
        "        input_size = (self.latent_dim,)\n",
        "#      summary(self.cuda(), input_size=input_size)\n",
        "      summary(self.cuda(), input_size=input_size)\n",
        "\n",
        "GeneratorFactory = {\n",
        "    'Generator_Conv': Generator_Conv,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31I7sXf-nzIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "f3590534-5158-4fd4-8db0-8bb7b4cf7224"
      },
      "source": [
        "test_model = Generator_Conv(512)\n",
        "test_model.print_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator_Conv(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(256, 256, kernel_size=(6, 6), stride=(2, 2), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): Tanh()\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "   ConvTranspose2d-1            [-1, 256, 5, 5]       3,276,800\n",
            "       BatchNorm2d-2            [-1, 256, 5, 5]             512\n",
            "              ReLU-3            [-1, 256, 5, 5]               0\n",
            "   ConvTranspose2d-4          [-1, 256, 14, 14]       2,359,296\n",
            "       BatchNorm2d-5          [-1, 256, 14, 14]             512\n",
            "              ReLU-6          [-1, 256, 14, 14]               0\n",
            "   ConvTranspose2d-7          [-1, 128, 31, 31]         819,200\n",
            "       BatchNorm2d-8          [-1, 128, 31, 31]             256\n",
            "              ReLU-9          [-1, 128, 31, 31]               0\n",
            "  ConvTranspose2d-10           [-1, 64, 63, 63]          73,728\n",
            "      BatchNorm2d-11           [-1, 64, 63, 63]             128\n",
            "             ReLU-12           [-1, 64, 63, 63]               0\n",
            "  ConvTranspose2d-13          [-1, 3, 128, 128]           3,072\n",
            "      BatchNorm2d-14          [-1, 3, 128, 128]               6\n",
            "             Tanh-15          [-1, 3, 128, 128]               0\n",
            "================================================================\n",
            "Total params: 6,533,510\n",
            "Trainable params: 6,533,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 11.05\n",
            "Params size (MB): 24.92\n",
            "Estimated Total Size (MB): 35.97\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtDTZOxngB_b",
        "colab_type": "text"
      },
      "source": [
        "# Discriminators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVjW4wBIpw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator_Conv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator_Conv, self).__init__()\n",
        "        ndf = 128\n",
        "        nc = 3\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc=1) x 28 x 28\n",
        "            nn.Conv2d(nc, ndf, 4, stride=2, padding=2, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            # state size. (ndf) x 16 x 16\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 8 x 8\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 8, 1, 3, stride=1, padding=0, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(36, 1),\n",
        "            \n",
        "            \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "    def print_summary(self, input_size=(3, 128, 128)):\n",
        "      from torchsummary import summary\n",
        "      print(self)\n",
        "      summary(self.cuda(), input_size=input_size)\n",
        "\n",
        "# https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=pcPCt8JG7tI-&line=1&uniqifier=1\n",
        "DiscriminatorFactory = {\n",
        "    'Discriminator_Conv': Discriminator_Conv,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh9uedXvIpxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "b5ac944f-f301-4956-dc9e-abe4bc1b054e"
      },
      "source": [
        "test_model = Discriminator_Conv()\n",
        "test_model.print_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator_Conv(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(1024, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (13): Flatten()\n",
            "    (14): Linear(in_features=36, out_features=1, bias=True)\n",
            "    (15): Sigmoid()\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 65, 65]           6,144\n",
            "         LeakyReLU-2          [-1, 128, 65, 65]               0\n",
            "            Conv2d-3          [-1, 256, 32, 32]         524,288\n",
            "       BatchNorm2d-4          [-1, 256, 32, 32]             512\n",
            "         LeakyReLU-5          [-1, 256, 32, 32]               0\n",
            "            Conv2d-6          [-1, 512, 16, 16]       2,097,152\n",
            "       BatchNorm2d-7          [-1, 512, 16, 16]           1,024\n",
            "         LeakyReLU-8          [-1, 512, 16, 16]               0\n",
            "            Conv2d-9           [-1, 1024, 8, 8]       8,388,608\n",
            "      BatchNorm2d-10           [-1, 1024, 8, 8]           2,048\n",
            "        LeakyReLU-11           [-1, 1024, 8, 8]               0\n",
            "           Conv2d-12              [-1, 1, 6, 6]           9,216\n",
            "        LeakyReLU-13              [-1, 1, 6, 6]               0\n",
            "          Flatten-14                   [-1, 36]               0\n",
            "           Linear-15                    [-1, 1]              37\n",
            "          Sigmoid-16                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 11,029,029\n",
            "Trainable params: 11,029,029\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 18.75\n",
            "Params size (MB): 42.07\n",
            "Estimated Total Size (MB): 61.01\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJzLgOPSwC7k",
        "colab_type": "text"
      },
      "source": [
        "## Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGt4wmibwMfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class UnitAspectRatioPaddingTransform:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        d_w_h = x.width - x.height\n",
        "        \n",
        "        if d_w_h == 0:\n",
        "            return x\n",
        "        \n",
        "        pad_l = 0\n",
        "        pad_t = 0\n",
        "        pad_r = 0\n",
        "        pad_b = 0\n",
        "        \n",
        "        if d_w_h > 0:\n",
        "            # wider\n",
        "            pad_t = int(np.ceil(d_w_h/2))\n",
        "            pad_b = int(np.floor(d_w_h/2))\n",
        "        elif d_w_h < 0:\n",
        "            # taller\n",
        "            pad_l = int(np.ceil(-d_w_h/2))\n",
        "            pad_r = int(np.floor(-d_w_h/2))\n",
        "\n",
        "        # TF.pad calls np.pad() underneath\n",
        "        return TF.pad(x, padding=(pad_l, pad_t, pad_r, pad_b), padding_mode='edge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KVKS7HRgK9s",
        "colab_type": "text"
      },
      "source": [
        "# Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5E4IpT-7TuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metric_name = \"exp_avg_distance\"\n",
        "metric_mode = \"min\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZvqIP6QIpw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANdam(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, hparams, data_dir=None):\n",
        "        super(GANdam, self).__init__()\n",
        "\n",
        "        self.hparams = hparams if isinstance(hparams, Namespace) else Namespace(**hparams)\n",
        "        self.data_dir = data_dir or os.getcwd()\n",
        "        \n",
        "        # networks\n",
        "        mnist_shape = (1, 28, 28)\n",
        "        self.generator = GeneratorFactory[self.hparams.generator](latent_dim=self.hparams.latent_dim)\n",
        "        self.discriminator = DiscriminatorFactory[self.hparams.discriminator]()\n",
        "        \n",
        "        # cache for generated images\n",
        "        self.generated_imgs = None\n",
        "        self.last_imgs = None\n",
        " \n",
        "        self.gen_img_list = list()\n",
        "\n",
        "        # exponential average metric\n",
        "        self.exp_avg_metric_val = None\n",
        "        \n",
        "    def forward(self, z):\n",
        "        return self.generator(z)\n",
        "    \n",
        "    def adversarial_loss(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        b1 = self.hparams.b1\n",
        "        b2 = self.hparams.b2\n",
        "        \n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=self.hparams.lr_g, betas=(b1, b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=self.hparams.lr_d, betas=(b1, b2))\n",
        "        \n",
        "        return [opt_g, opt_d], []\n",
        "    \n",
        "    def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "        #train generator\n",
        "        imgs, classes = batch\n",
        "        self.last_imgs = imgs\n",
        "        \n",
        "        latent_samplings = torch.randn(imgs.shape[0], self.hparams.latent_dim, device=self.device)\n",
        "        #detach() to stop gradient backprop to the generator\n",
        "        self.img_generated = self.generator(latent_samplings).detach()\n",
        "        \n",
        "        real_labels = torch.ones(imgs.shape[0], 1, device=self.device)\n",
        "        \n",
        "        if optimizer_idx == 0:\n",
        "            g_loss = self.adversarial_loss(self.discriminator(self.generator(latent_samplings)), real_labels)\n",
        "            \n",
        "            tqdm_dict = {'g_loss': g_loss}\n",
        "            output = OrderedDict({\n",
        "                'loss': g_loss,\n",
        "                'progress_bar': tqdm_dict,\n",
        "                'log': tqdm_dict\n",
        "            })\n",
        "            self.current_g_loss = g_loss\n",
        "        \n",
        "        elif optimizer_idx == 1:\n",
        "            d_loss_real = self.adversarial_loss(self.discriminator(imgs), real_labels)\n",
        "            \n",
        "            fake_labels = torch.zeros(imgs.shape[0], 1, device=self.device)\n",
        "            d_loss_fake = self.adversarial_loss(self.discriminator(self.img_generated), fake_labels)\n",
        "            \n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "\n",
        "            # measures the min/max equilibrium\n",
        "            self.d_eq_distance = torch.abs(d_loss - 0.5)\n",
        "            self.exp_avg_distance = self.exp_avg_metric(self.d_eq_distance)\n",
        "            \n",
        "            # d_eq_distance_metric is a duplication of d_eq_distance\n",
        "            # It is required for a workaround relating to HParams metrics in TensorBoard\n",
        "            # https://github.com/PyTorchLightning/pytorch-lightning/issues/1228#issuecomment-659175500\n",
        "            tqdm_dict = {'d_loss': d_loss, 'd_eq_distance': self.d_eq_distance, metric_name: self.exp_avg_distance}\n",
        "            output = OrderedDict({\n",
        "                'loss': d_loss,\n",
        "                'progress_bar': tqdm_dict,\n",
        "                'log': tqdm_dict\n",
        "            })\n",
        "            self.current_d_loss = d_loss\n",
        "          \n",
        "\n",
        "        return output\n",
        "    \n",
        "    def exp_avg_metric(self, val, alpha = 0.1):\n",
        "      if self.exp_avg_metric_val == None:\n",
        "        self.exp_avg_metric_val = val\n",
        "\n",
        "      self.exp_avg_metric_val = alpha * val + (1 - alpha) * self.exp_avg_metric_val\n",
        "\n",
        "      return self.exp_avg_metric_val\n",
        "\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        transform = transforms.Compose([UnitAspectRatioPaddingTransform(),\n",
        "                                transforms.Resize(128, interpolation=2),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "        dataset = ImageFolder(dataset_path, transform=transform)\n",
        "\n",
        "        return DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        z = torch.randn(16, self.hparams.latent_dim, device=self.device)\n",
        "        sample_imgs = self(z)\n",
        "        if len(sample_imgs.shape) < 4:\n",
        "          sample_imgs = sample_imgs.unsqueeze(1) #adding the color channel\n",
        "\n",
        "\n",
        "        grid = torchvision.utils.make_grid(sample_imgs, nrow=4, padding=5, normalize=True)\n",
        "#         plt.imshow(np.transpose(np.asarray(grid),(1,2,0)))\n",
        "        self.gen_img_list.append(grid.detach().cpu())\n",
        "\n",
        "        self.logger.experiment.add_image(f'generated_images', grid, self.current_epoch)\n",
        "\n",
        "    # A workaround for TB, see metric_name above\n",
        "    def on_fit_start(self):\n",
        "      metric_placeholder = {metric_name: 50}\n",
        "      self.logger.log_hyperparams(self.hparams, metrics=metric_placeholder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXSNO3i0IpxA",
        "colab_type": "text"
      },
      "source": [
        "# Lightning Trial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10W9jMfQjj7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_fname = \"checkpoint\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NXRHQrK5dZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TuneCallback(Callback):\n",
        "\n",
        "  def on_epoch_end(self, trainer, pl_module):\n",
        "    # How to save checkpoints:\n",
        "    # https://github.com/ray-project/ray/blob/9b1772253f47d20d8aa1bc727d67630b2026b9e5/python/ray/tune/examples/mnist_pytorch_lightning.py#L158\n",
        "\n",
        "    # path = tune.make_checkpoint_dir(trainer.global_step)\n",
        "    # path = tune.checkpoint_dir()\n",
        "    # trainer.save_checkpoint(os.path.join(path, checkpoint_fname))\n",
        "    # tune.save_checkpoint(path)\n",
        "\n",
        "    with tune.checkpoint_dir(trainer.global_step) as path:\n",
        "      trainer.save_checkpoint(os.path.join(path, checkpoint_fname))\n",
        "\n",
        "    # reports needs to be called after tune.save_checkpoint(path)\n",
        "    report_dict = {\n",
        "        metric_name : pl_module.exp_avg_distance.item(),\n",
        "        'loss_d' : pl_module.current_d_loss.item(),\n",
        "        'loss_g' : pl_module.current_g_loss.item(),\n",
        "        'current_epoch' : pl_module.current_epoch,\n",
        "    }\n",
        "    tune.report(**report_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKkou4Urk4Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyTrainableClass(Trainable):\n",
        "  # https://docs.ray.io/en/latest/tune/api_docs/trainable.html?highlight=get_trial_dir#ray.tune.Trainable.trial_name\n",
        "    \"\"\"Example agent whose learning curve is a random sigmoid.\n",
        "    The dummy hyperparameters \"width\" and \"height\" determine the slope and\n",
        "    maximum reward value reached.\n",
        "    \"\"\"\n",
        "\n",
        "    # checkpoint files aren't removed\n",
        "\n",
        "    def setup(self, config):\n",
        "      self.num_gpus = config[\"num_gpus\"]\n",
        "\n",
        "      self.trainer = pl.Trainer(\n",
        "        gpus=self.num_gpus,\n",
        "         progress_bar_refresh_rate=100,\n",
        "         logger=TensorBoardLogger(\n",
        "             save_dir=self.logdir,\n",
        "             name=\"\",\n",
        "             version=\".\"),\n",
        "         max_epochs=1, #single step\n",
        "         checkpoint_callback=False, # checkpoint saved by ray\n",
        "         )\n",
        "      \n",
        "      self.model = GANdam(Namespace(**config), data_dir=config[\"data_dir\"])\n",
        "\n",
        "      self.timestep = 0\n",
        "\n",
        "    def step(self):\n",
        "      # epoch isn't incremented in the\n",
        "      self.trainer.fit(self.model)\n",
        "      self.timestep = self.trainer.global_step\n",
        "\n",
        "      result = {\n",
        "        metric_name : self.model.exp_avg_distance.item(),\n",
        "        'loss_d' : self.model.current_d_loss.item(),\n",
        "        'loss_g' : self.model.current_g_loss.item(),\n",
        "        'current_epoch' : self.model.current_epoch,\n",
        "      }\n",
        "\n",
        "      return result\n",
        "\n",
        "    def save_checkpoint(self, checkpoint_dir):\n",
        "      self.trainer.save_checkpoint(os.path.join(checkpoint_dir, checkpoint_fname))\n",
        "\n",
        "    def load_checkpoint(self, checkpoint_path):\n",
        "      chkp_file_path = os.path.join(checkpoint_path, checkpoint_fname)\n",
        "      self.model.load_from_checkpoint(chkp_file_path)\n",
        "\n",
        "      self.trainer = pl.Trainer(\n",
        "              resume_from_checkpoint=chkp_file_path,\n",
        "              gpus=self.num_gpus,\n",
        "               progress_bar_refresh_rate=100,\n",
        "               logger=TensorBoardLogger(\n",
        "                   save_dir=self.logdir,\n",
        "                   name=\"\",\n",
        "                   version=\".\"),\n",
        "               max_epochs=1, #single step\n",
        "              #  max_epochs=self.timestep+1, #single step\n",
        "               checkpoint_callback=False, # checkpoint saved by ray\n",
        "               )\n",
        "\n",
        "      self.timestep = self.trainer.global_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5sdlHcM58Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gandam(config, checkpoint_dir=None, data_dir=None, num_epochs=10, num_gpus=1):\n",
        "\n",
        "  gan_model = GANdam(Namespace(**config), data_dir=data_dir)\n",
        "\n",
        "  if checkpoint_dir:\n",
        "    chkp_file_path = os.path.join(checkpoint_dir, checkpoint_fname)\n",
        "    gan_model.load_from_checkpoint(chkp_file_path)\n",
        "\n",
        "  else:\n",
        "    chkp_file_path = None\n",
        "    \n",
        "  trainer = pl.Trainer(\n",
        "                  resume_from_checkpoint=chkp_file_path,\n",
        "                  gpus=num_gpus,\n",
        "                   progress_bar_refresh_rate=100,\n",
        "                   logger=TensorBoardLogger(\n",
        "                       save_dir=os.path.join(log_path, self.trial_name),\n",
        "                       name=\"\",\n",
        "                       version=\".\"),\n",
        "                   max_epochs=num_epochs,\n",
        "                   checkpoint_callback=False)\n",
        "\n",
        "\n",
        "  trainer.fit(gan_model)\n",
        "\n",
        "  return {\"model\" : gan_model}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNI_-UOjg1Pi",
        "colab_type": "text"
      },
      "source": [
        "# Ray Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db1sUEZYcO-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://docs.ray.io/en/master/_modules/ray/tune/progress_reporter.html#JupyterNotebookReporter\n",
        "# reporter = CLIReporter(\n",
        "reporter = JupyterNotebookReporter(overwrite=True,\n",
        "    metric_columns=[metric_name, \"loss_d\", \"loss_g\", \"current_epoch\", \"training_iteration\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8tWR0JS7AwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_gandam_pbt(num_samples=3, num_epochs=5, cpus_per_trial=1, gpus_per_trial=1):\n",
        "\n",
        "  # result properties: https://github.com/ray-project/ray/blob/master/python/ray/tune/result.py\n",
        "  def trail_stopper(trial_id, result):\n",
        "    stop = False\n",
        "    stop |= result[\"training_iteration\"] > num_epochs\n",
        "    # stop |= result[metric_name] > 0.499\n",
        "    return stop\n",
        "\n",
        "  def rand_log_linear_lr(max=0.1, min=0.00001):\n",
        "    return 10**(np.random.uniform(low=np.log10(min), high=np.log10(max))) \n",
        "\n",
        "\n",
        "  scheduler = PopulationBasedTraining(\n",
        "    time_attr=\"training_iteration\",\n",
        "    metric=metric_name,\n",
        "    mode=metric_mode,\n",
        "    perturbation_interval=6,\n",
        "    hyperparam_mutations={\n",
        "        \"lr_d\": lambda: rand_log_linear_lr(max=0.1, min=0.00001),\n",
        "        \"lr_g\": lambda: rand_log_linear_lr(max=0.1, min=0.00001),\n",
        "  })\n",
        "\n",
        "  config = {\n",
        "      \"generator\": \"Generator_Conv\",\n",
        "      \"discriminator\": \"Discriminator_Conv\",\n",
        "      'batch_size': 512,\n",
        "      'latent_dim': 512,\n",
        "      \"lr_d\": tune.sample_from(lambda spec: rand_log_linear_lr(max=0.01, min=0.0001)),\n",
        "      \"lr_g\": tune.sample_from(lambda spec: rand_log_linear_lr(max=0.01, min=0.0001)),\n",
        "      'b1': 0.5,\n",
        "      'b2': 0.999,\n",
        "      # \"batch_size\": tune.choice([32, 64, 128]),\n",
        "      \"num_gpus\": 1,\n",
        "      \"data_dir\": data_dir\n",
        "\n",
        "  }\n",
        "\n",
        "  result = tune.run(\n",
        "                 MyTrainableClass,\n",
        "                 resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
        "                 stop=trail_stopper,\n",
        "                 config=config,\n",
        "                 num_samples=num_samples,\n",
        "                 scheduler=scheduler,\n",
        "                 queue_trials=True,\n",
        "                 progress_reporter=reporter,\n",
        "                 local_dir=log_path,\n",
        "                 checkpoint_at_end=True,\n",
        "                 verbose=2,\n",
        "                 name=\"tune_pbt_gandam\")\n",
        "  \n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8zRpFRihKs9",
        "colab_type": "text"
      },
      "source": [
        "# Start TensorBoard & HParam Sweeping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai2nVlK9-nUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8f98862-09c8-407e-f2dc-7a49880d3488"
      },
      "source": [
        "# Start tensorboard.\n",
        "%reload_ext tensorboard\n",
        "\n",
        "#watch -n 1 timeout -sHUP 1m tensorboard --logdir .\n",
        "def tfb_restarter():\n",
        "    tfb_shell_str = \"while true; do timeout -sHUP 1m tensorboard --logdir \" + log_path.replace(\" \", \"\\ \") + \" --port=6006; done\"\n",
        "    os.popen(tfb_shell_str).wait()\n",
        "\n",
        "thread1 = threading.Thread(target = tfb_restarter)\n",
        "thread1.start()\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "# https://github.com/tensorflow/tensorboard/blob/master/tensorboard/notebook.py\n",
        "notebook.display(port=6006, height=1000) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-6:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-40-6f797c9fb07e>\", line 7, in tfb_restarter\n",
            "    os.popen(tfb_shell_str).wait()\n",
            "  File \"/usr/lib/python3.6/os.py\", line 1008, in __getattr__\n",
            "    return getattr(self._stream, name)\n",
            "AttributeError: '_io.TextIOWrapper' object has no attribute 'wait'\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selecting TensorBoard with logdir /content/gdrive/My Drive/Colab_results/12-08-2020_11_18_17-GANdam_BAYSIAN_SWEEP (started 0:52:37 ago; port 6006, pid 97046).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '1000');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTkRlpScIpxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "outputId": "0794ead1-099f-4297-c39c-35a9b62ddcbe"
      },
      "source": [
        "%%capture --no-display --no-stderr\n",
        "analysis = tune_gandam_pbt(num_samples=4, cpus_per_trial=2, gpus_per_trial= 1, num_epochs=30)\n",
        "# analysis = tune_dcgan_mstop(num_samples=5, num_epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 5.7/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 7 perturbs<br>Resources requested: 4/2 CPUs, 2/1 GPUs, 0.0/7.18 GiB heap, 0.0/2.44 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /content/gdrive/My Drive/Colab_results/12-08-2020_15_54_15-GANdam_BAYSIAN_SWEEP/tune_pbt_gandam<br>Number of trials: 4 (1 ERROR, 1 PAUSED, 2 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">       lr_d</th><th style=\"text-align: right;\">       lr_g</th><th style=\"text-align: right;\">  exp_avg_distance</th><th style=\"text-align: right;\">  loss_d</th><th style=\"text-align: right;\">  loss_g</th><th style=\"text-align: right;\">  current_epoch</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>MyTrainableClass_1fe01_00000</td><td>ERROR   </td><td>                 </td><td style=\"text-align: right;\">0.00319706 </td><td style=\"text-align: right;\">0.00789307 </td><td style=\"text-align: right;\">          0.342204</td><td style=\"text-align: right;\">0.107164</td><td style=\"text-align: right;\"> 6.72367</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                  31</td></tr>\n",
              "<tr><td>MyTrainableClass_1fe01_00001</td><td>RUNNING </td><td>172.28.0.2:381791</td><td style=\"text-align: right;\">0.000158201</td><td style=\"text-align: right;\">0.000732072</td><td style=\"text-align: right;\">          0.284638</td><td style=\"text-align: right;\">0.263121</td><td style=\"text-align: right;\"> 4.46904</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                  15</td></tr>\n",
              "<tr><td>MyTrainableClass_1fe01_00002</td><td>RUNNING </td><td>                 </td><td style=\"text-align: right;\">0.000158201</td><td style=\"text-align: right;\">0.000328182</td><td style=\"text-align: right;\">          0.290999</td><td style=\"text-align: right;\">0.138008</td><td style=\"text-align: right;\"> 4.01695</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                  18</td></tr>\n",
              "<tr><td>MyTrainableClass_1fe01_00003</td><td>PAUSED  </td><td>                 </td><td style=\"text-align: right;\">0.000131834</td><td style=\"text-align: right;\">0.00091509 </td><td style=\"text-align: right;\">          0.145481</td><td style=\"text-align: right;\">0.307735</td><td style=\"text-align: right;\"> 1.32954</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                  12</td></tr>\n",
              "</tbody>\n",
              "</table><br>Number of errored trials: 1<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                            </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>MyTrainableClass_1fe01_00000</td><td style=\"text-align: right;\">           1</td><td>/content/gdrive/My Drive/Colab_results/12-08-2020_15_54_15-GANdam_BAYSIAN_SWEEP/tune_pbt_gandam/MyTrainableClass_0_lr_d=0.0031971,lr_g=0.0078931_2020-08-12_15-54-37kqs8xg0j/error.txt</td></tr>\n",
              "</tbody>\n",
              "</table><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(pid=381791) \n",
            "(pid=381791)   | Name          | Type               | Params\n",
            "(pid=381791) -----------------------------------------------------\n",
            "(pid=381791) 0 | generator     | Generator_Conv     | 6 M   \n",
            "(pid=381791) 1 | discriminator | Discriminator_Conv | 11 M  \n",
            "2020-08-13 02:20:43,088\tINFO (unknown file):0 -- gc.collect() freed 66 refs in 0.13033863599412143 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2e031989f684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_gandam_pbt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# analysis = tune_dcgan_mstop(num_samples=5, num_epochs=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-12a7fd887765>\u001b[0m in \u001b[0;36mtune_gandam_pbt\u001b[0;34m(num_samples, num_epochs, cpus_per_trial, gpus_per_trial)\u001b[0m\n\u001b[1;32m     49\u001b[0m                  \u001b[0mcheckpoint_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                  name=\"tune_pbt_gandam\")\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, log_to_file, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1685\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m         )\n\u001b[1;32m   1689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkkI6aazhbmt",
        "colab_type": "text"
      },
      "source": [
        "# Training - Best HParams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-bhldDfKR8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8882874a-28f2-4e7d-e6cb-a80fc3b3b45b"
      },
      "source": [
        "print(\"best trial name: \" + str(analysis.get_best_trial(metric=metric_name, mode=metric_mode, scope='last')))\n",
        "\n",
        "best_hyperparameters = analysis.get_best_config(metric=metric_name, mode=metric_mode, scope='last')\n",
        "print(\"best hyperparameters: \" + str(best_hyperparameters))\n",
        "\n",
        "gan_model = GANdam(Namespace(**best_hyperparameters), data_dir=data_dir)\n",
        "\n",
        "# Restore Best Result\n",
        "best_checkpoint_path = os.path.abspath(analysis.get_best_logdir(metric=metric_name, mode=metric_mode, scope='last'))\n",
        "chkp_file_path = os.path.join(best_checkpoint_path, \"checkpoint\", checkpoint_fname)\n",
        "\n",
        "gan_model.load_from_checkpoint(chkp_file_path)\n",
        "  \n",
        "trainer = pl.Trainer(\n",
        "                resume_from_checkpoint=chkp_file_path,\n",
        "                gpus=1,\n",
        "                default_root_dir=os.path.join(log_path, \"lightning_log_final\"),\n",
        "                checkpoint_callback=False,\n",
        "                max_epochs=0)\n",
        "trainer.fit(gan_model)\n",
        "\n",
        "# #Re-Train\n",
        "# gan_model = DCGAN(Namespace(**best_hyperparameters))\n",
        "# trainer = pl.Trainer(gpus=1, max_epochs=20, default_root_dir=os.path.join(log_path, \"lightning_log_final\"))\n",
        "# trainer.fit(gan_model)\n",
        "\n",
        "# print(\"d_loss: \", gan_model.current_d_loss.item(), \" g_loss: \", gan_model.current_g_loss.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-30e3e5209f7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best trial name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best hyperparameters: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'analysis' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xOOnCTrrJan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = torch.randn(8 * 8, gan_model.hparams.latent_dim, device=gan_model.device)\n",
        "sample_imgs = gan_model(z)\n",
        "if len(sample_imgs.shape) < 4:\n",
        "  sample_imgs = sample_imgs.unsqueeze(1) #adding the color channel\n",
        "grid = torchvision.utils.make_grid(sample_imgs.detach(), padding=5, normalize=True)\n",
        "fig = plt.figure()\n",
        "plt.imshow(np.transpose(grid,(1,2,0)), animated=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EFk1ejfEJLj",
        "colab_type": "text"
      },
      "source": [
        "### Animation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uXvyNXkLtz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fig = plt.figure()\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in gan_model.gen_img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuEqKv2MlAp-",
        "colab_type": "text"
      },
      "source": [
        "# Wrapping Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY9izOhnqcdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch-lightning.readthedocs.io/en/latest/weights_loading.html\n",
        "trainer.save_checkpoint(os.path.join(log_path, \"model.ckpt\"))\n",
        "\n",
        "import pickle\n",
        "pickle.dump( best_hyperparameters, open(os.path.join(log_path, \"hparams.pkl\"), \"wb\" ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJRKSGOkw2Fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFcVY6nPJW6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ls_dirs(path):\n",
        "  relative_paths = [os.path.join(path, i) for i in os.listdir(path)]\n",
        "  return [i for i in relative_paths if os.path.isdir(i)]\n",
        "\n",
        "for exp_dir in ls_dirs(log_path):\n",
        "  for trail_dir in ls_dirs(os.path.join(log_path, exp_dir)):\n",
        "        redundant_chkp_path = os.path.join(trail_dir, \"checkpoint\")\n",
        "        if os.path.isdir(redundant_chkp_path) and redundant_chkp_path != best_checkpoint_path:\n",
        "          print(\"removing \" + redundant_chkp_path)\n",
        "          shutil.rmtree(redundant_chkp_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6R_c842lGPL",
        "colab_type": "text"
      },
      "source": [
        "# Useful Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj9q_HomPHC4",
        "colab_type": "text"
      },
      "source": [
        "[Lightning Callbacks](https://github.com/PyTorchLightning/pytorch-lightning/blob/0.8.5/pytorch_lightning/callbacks/base.py)\n",
        "\n",
        "[Lightning Trainer](https://github.com/PyTorchLightning/pytorch-lightning/blob/e1bc208f66891e22f0139619a1be5c06235a0f34/pytorch_lightning/trainer/trainer.py)\n",
        "\n",
        "[Lightning Module](https://github.com/PyTorchLightning/pytorch-lightning/blob/1369012bc71f257dcf7423ec65146d055ddc1cc7/pytorch_lightning/core/lightning.py#L1574)\n",
        "\n",
        "[Lightning Logger](https://github.com/PyTorchLightning/pytorch-lightning/blob/62ce00f96c09de6d137c810921a6cd9e7b60aff5/pytorch_lightning/trainer/logging.py)\n",
        "\n",
        "[Lightning HParams Logging Issue](https://github.com/PyTorchLightning/pytorch-lightning/issues/1228)\n",
        "\n",
        "[Ray Lightning Mnist](https://github.com/krfricke/ray/blob/5921475d9fa7b2bcb62d2413636f8e656a00f688/python/ray/tune/examples/mnist_pytorch_lightning.py)\n",
        "\n",
        "[Ray Session](https://github.com/ray-project/ray/blob/d35f0e40d07bab06b41ce5493c2f50b6725a1857/python/ray/tune/session.py)\n",
        "\n",
        "[Ray Result Dict](https://github.com/ray-project/ray/blob/master/python/ray/tune/result.py)\n",
        "\n",
        "[Ray Function API](https://docs.ray.io/en/master/tune/api_docs/trainable.html#function-api)\n",
        "\n",
        "[Ray PBT](https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html#replaying-a-pbt-run)\n",
        "\n",
        "[Ray Search Space](https://github.com/ray-project/ray/blob/4bc1d7c043cca03a743fbeb98b0434fecafa7001/doc/source/tune/api_docs/grid_random.rst)\n",
        "\n",
        "[Ray Memory](https://docs.ray.io/en/master/memory-management.html)\n",
        "\n",
        "[Ray PBT Example](https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/pbt_dcgan_mnist/pbt_dcgan_mnist.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q4UwbrWaHDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}